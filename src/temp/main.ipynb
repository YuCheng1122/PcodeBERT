{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假設 utils 模組中的函數能夠被正確導入\n",
    "# 這需要您確保 utils.py 在 Python 的搜尋路徑中\n",
    "from utils import iterate_json_files, extract_sentences_from_file, read_filenames_from_csv\n",
    "\n",
    "# --- 您的常數設定 ---\n",
    "CSV_PATH = Path(\"/home/tommy/Projects/PcodeBERT/dataset/csv/merged_adjusted_filtered.csv\")\n",
    "RAW_DATA_PATH = Path(\"/home/tommy/Projects/PcodeBERT/reverse/new/results\")\n",
    "ERROR_LOG_PATH = Path(\"/home/tommy/Projects/PcodeBERT/outputs/preprocessed/error_log.txt\") # 假設需要這個參數\n",
    "TARGET_CPU = \"x86_64\"\n",
    "TARGET_TOKEN = \"INT_\"\n",
    "\n",
    "def find_raw_files_with_token(csv_path: Path, root_dir: Path, error_log_path: Path, cpu_to_process: str, target_token: str, limit: int = 10):\n",
    "    \"\"\"\n",
    "    遍歷原始 JSON 檔案，篩選出其指令中包含特定 token 的檔名。\n",
    "    \"\"\"\n",
    "    print(f\"--- 開始尋找包含 '{target_token}' token 的原始檔案 (CPU: {cpu_to_process}) ---\")\n",
    "    \n",
    "    # 使用原本腳本中的函數來產生檔案數據的迭代器\n",
    "    # file_iterator 預期回傳 (file_name, json_data_string)\n",
    "    file_iterator = iterate_json_files(csv_path, root_dir, error_log_path, cpu_filter=cpu_to_process)\n",
    "    \n",
    "    found_filenames = []\n",
    "    \n",
    "    # 預先計算總檔案數以設定進度條\n",
    "    try:\n",
    "        total_files = len(read_filenames_from_csv(csv_path, cpu_filter=cpu_to_process))\n",
    "    except:\n",
    "        # 如果無法計算總數，則不顯示進度條\n",
    "        total_files = None\n",
    "        print(\"Warning: Could not get total file count for progress bar.\")\n",
    "\n",
    "    # 進行檔案處理和篩選\n",
    "    for file_name, json_data_string in tqdm(file_iterator, total=total_files, desc=\"Searching files\"):\n",
    "        \n",
    "        # 1. 使用原本腳本中的函數將原始資料轉換為句子列表 (token list of lists)\n",
    "        # 假設 extract_sentences_from_file 接受原始檔案數據 (這裡假設是 json_data_string)\n",
    "        sentences_from_file = extract_sentences_from_file((file_name, json_data_string))\n",
    "        \n",
    "        if sentences_from_file:\n",
    "            # 2. 檢查這些句子中是否有包含目標 token\n",
    "            token_found = False\n",
    "            \n",
    "            # sentences_from_file 預期是 List[List[Token]]\n",
    "            for sentence in sentences_from_file:\n",
    "                if target_token in sentence:\n",
    "                    token_found = True\n",
    "                    break # 找到一個句子包含 token 即可\n",
    "            \n",
    "            # 3. 如果找到，則記錄檔名\n",
    "            if token_found:\n",
    "                found_filenames.append(file_name)\n",
    "                \n",
    "                # 達到數量限制則停止\n",
    "                if len(found_filenames) >= limit:\n",
    "                    break\n",
    "\n",
    "    return found_filenames\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 執行篩選\n",
    "    target_filenames = find_raw_files_with_token(\n",
    "        csv_path=CSV_PATH, \n",
    "        root_dir=RAW_DATA_PATH, \n",
    "        error_log_path=ERROR_LOG_PATH, \n",
    "        cpu_to_process=TARGET_CPU, \n",
    "        target_token=TARGET_TOKEN, \n",
    "        limit=10\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"✅ 已找到包含 '{TARGET_TOKEN}' token 的原始檔案名 ({len(target_filenames)} 個):\")\n",
    "    \n",
    "    if target_filenames:\n",
    "        for i, filename in enumerate(target_filenames):\n",
    "            print(f\"   {i+1}. {filename}\")\n",
    "    else:\n",
    "        print(\"   ❌ 未找到符合條件的檔案。\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Any, List, Union\n",
    "\n",
    "file = \"/home/tommy/Projects/PcodeBERT/outputs/preprocessed/pcode_corpus_x86_64_new_data.pkl\"\n",
    "\n",
    "total_batches = 0\n",
    "total_sentences_checked = 0\n",
    "\n",
    "print(f\"--- 檔案結構簡潔檢查: {file} ---\")\n",
    "\n",
    "with open(file, \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            # 每次成功呼叫 load()，代表載入了一個獨立的序列化物件 (一個 Batch)\n",
    "            corpus_batch: Any = pickle.load(f)\n",
    "            total_batches += 1\n",
    "            \n",
    "            # --- 新增的結構檢查與資訊輸出 ---\n",
    "            batch_type_str = f\"Batch {total_batches} ({type(corpus_batch).__name__}, len={len(corpus_batch) if hasattr(corpus_batch, '__len__') else 'N/A'}): \"\n",
    "            \n",
    "            if isinstance(corpus_batch, list) and corpus_batch:\n",
    "                first_element = corpus_batch[0]\n",
    "                \n",
    "                if isinstance(first_element, list):\n",
    "                    # 判斷為巢狀結構：List[List[Token]]\n",
    "                    print(batch_type_str + \"✅ 結構: List[List[Token]] (2D)\")\n",
    "                    # 巢狀結構，計算總和\n",
    "                    batch_sentences = sum(len(sublist) for sublist in corpus_batch if isinstance(sublist, list))\n",
    "                    print(f\"    - 句子範例: {first_element[:5]}...\")\n",
    "                else:\n",
    "                    # 判斷為單層結構：List[Token]\n",
    "                    print(batch_type_str + \"❌ 結構: List[Token] (1D) - 警告：句子可能被展平。\")\n",
    "                    batch_sentences = len(corpus_batch)\n",
    "                    print(f\"    - 元素範例: {corpus_batch[:5]}...\")\n",
    "            else:\n",
    "                # 非列表或其他非預期結構\n",
    "                print(batch_type_str + \"❓ 結構: 非列表或為空。\")\n",
    "                batch_sentences = 0\n",
    "            \n",
    "            total_sentences_checked += batch_sentences\n",
    "            \n",
    "        except EOFError:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading batch {total_batches + 1}: {e}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n--- 最終總結 ---\")\n",
    "print(f\"檔案路徑: {file}\")\n",
    "print(f\"找到的總 Batch (序列化物件) 數量: {total_batches}\")\n",
    "print(f\"總共計算到的句子數量: {total_sentences_checked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba14e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f5f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PcodeBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
